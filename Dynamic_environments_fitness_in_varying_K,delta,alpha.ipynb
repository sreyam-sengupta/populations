{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b7c5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random as rand\n",
    "from numba import jit,int64,float64\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as sciopt\n",
    "%matplotlib inline\n",
    "\n",
    "#To increase cell width:\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#Color-blind friendly colors to plot:\n",
    "# CB_colors = ['#377eb8', '#ff7f00', '#4daf4a','#f781bf', '#a65628', '#984ea3','#999999', '#e41a1c', '#dede00']\n",
    "# CB_colors.reverse()\n",
    "CB_colors = ['#00429d', '#93003a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3cf788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "K = 1; 0.5*dg/dt = 4000.0\n",
      "D = 25.0; 0.5*dg**2/dt = 1600.0000000000002\n"
     ]
    }
   ],
   "source": [
    "#The spacetime parameters. Let the population distribution of gene expression level be g:\n",
    "g_min = 0\n",
    "g_max = 100\n",
    "dg = 0.4\n",
    "#Defining a g_ghost which contains two extra `ghost' points at the edges:\n",
    "g_ghost = np.arange(g_min-dg,g_max+2*dg,dg)\n",
    "g = np.array(g_ghost[1:-1])\n",
    "#The peak of the unregulated distribution:\n",
    "g_peak = 0.5*(g_min+g_max)\n",
    "\n",
    "#Parameters:\n",
    "K = 1\n",
    "delta = 100\n",
    "alpha = 0.5\n",
    "\n",
    "#Constant environment, T fixed:\n",
    "dt = np.minimum(0.00005/K,0.01/delta)\n",
    "T = 10\n",
    "# #If tau is too large, we don't change:\n",
    "# num_cycles = 8\n",
    "# T = num_cycles*tau\n",
    "TimeRange = np.arange(0,T,dt)\n",
    "print(len(TimeRange))\n",
    "\n",
    "#Tolerance to calculate entropy:\n",
    "eps = 1e-100\n",
    "\n",
    "#The noise variance D:\n",
    "D = alpha*K*g_peak\n",
    "\n",
    "#Checks:\n",
    "print(f\"K = {K}; 0.5*dg/dt = {0.5*dg/dt}\")\n",
    "print(f\"D = {D}; 0.5*dg**2/dt = {0.5*dg**2/dt}\")\n",
    "\n",
    "#Stability check:\n",
    "flag_stability=0\n",
    "if (K>=int(0.5*dg/dt) or D>=int(0.5*dg**2/dt)):\n",
    "    flag_stability=1\n",
    "    print(\"Warning! FTCS unstable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4b19d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First derivative, central difference method (used in the potential term K*d/dg (g*P)):\n",
    "@jit(\"float64[:](float64[:],float64)\",nopython=True)\n",
    "def derv1(func,dx):\n",
    "    func_left = func[0:-2]\n",
    "    func_right = func[2:]\n",
    "    #Below we calculate the first derivative using the central difference method:\n",
    "    derivative = (func_right - func_left)/(2*dx)\n",
    "    return derivative\n",
    "\n",
    "#Second derivative using central difference, used in the diffusion term (D*d2/dg2 (P)):\n",
    "@jit(\"float64[:](float64[:],float64)\",nopython=True)\n",
    "def derv2(func,dx):\n",
    "    func_left = func[0:-2]\n",
    "    func_right = func[2:]\n",
    "    func_center = func[1:-1]\n",
    "    #Below we calculate the second derivative, again using central difference method:\n",
    "    derivative2 = (func_right + func_left - 2*func_center)/(dx**2)\n",
    "    return derivative2\n",
    "\n",
    "#Defining a Gaussian pdf - we'll need it for P(g,t=0), the initial distribution:\n",
    "@jit(nopython=True)\n",
    "def Gaussian(x,mu,sigma):\n",
    "    dist = 1/(sigma*np.sqrt(2*np.pi))*np.exp(-0.5*((x-mu)/sigma)**2)\n",
    "    return dist\n",
    "\n",
    "#The function to calculate <f> dynamically, i.e. int_g f(g,s) P(g,t):\n",
    "@jit(nopython=True)\n",
    "def mean_wrt_P(func,P,g):\n",
    "    integrand = func*P\n",
    "    integral = np.trapz(integrand,g)\n",
    "    return integral\n",
    "\n",
    "#Defining the fitness function:\n",
    "# @jit([\"float64[:](float64[:],float64,float64)\",\"float64(float64,float64,float64)\"],nopython=True)\n",
    "def fitness(g,s,delta):\n",
    "    fit = delta*(g*s/(400+s) - (2/17)*g/(1-g/(1.8*g_max)))/g_max\n",
    "    return fit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def discrete_entropy(p_dist):\n",
    "    p_dist = p_dist[np.where(np.clip(p_dist,eps,None)>eps)]\n",
    "    return np.sum(p_dist*np.log2(1/p_dist))\n",
    "\n",
    "@jit(nopython=True)\n",
    "def cont_entropy(p_dist):\n",
    "    p_dist = p_dist[np.where(np.clip(p_dist,eps,None)>eps)]\n",
    "    return np.trapz(p_dist*np.log2(1/p_dist),dx=dg)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def selection_const_noise(p0_unreg,p0_reg,s,K,alpha,delta,T,dt):\n",
    "    #First, time:\n",
    "#     dt = 0.0001/K\n",
    "    TimeRange = np.arange(0,T,dt)\n",
    "    \n",
    "    #Then, define the fitness function:\n",
    "    fit = delta*(g*s/(400+s) - (2/17)*g/(1-g/(1.8*g_max)))/g_max\n",
    "    g_reg = g[np.argmax(fit)]\n",
    "\n",
    "    #Now let's compare the effects of regulation vs selection:\n",
    "    p_unreg = p0_unreg\n",
    "    p_reg = p0_reg\n",
    "    flag_unreg = 0\n",
    "    flag_reg = 0\n",
    "    \n",
    "#     #Storing dynamic fitness:\n",
    "#     dyn_fit_unreg = np.zeros_like\n",
    "\n",
    "    #Now evolve it:\n",
    "    for t in range(len(TimeRange)):\n",
    "        #Constant noise:\n",
    "        D_unreg = alpha*K*g_peak\n",
    "        D_reg = alpha*K*g_peak\n",
    "\n",
    "    #     #Checks:\n",
    "    #     if (t%10==0):\n",
    "    #         print(f\"\\nt={t}; g_mean_unreg={round(g_mean_unreg,2)}; D_unreg={round(D_unreg,2)}; max allowed={0.5*dg**2/dt}\")\n",
    "    #         print(f\"t={t}; g_mean_reg={round(g_mean_reg,2)}; D_reg={round(D_reg,2)}; max allowed={0.5*dg**2/dt}\")        \n",
    "\n",
    "        #Now creating the expanded p's, with ghost points. The bulk points are the same in each. Unregulated:\n",
    "        p_unreg_ghost = np.zeros(len(p_unreg)+2)\n",
    "        p_unreg_ghost[1:-1] = p_unreg\n",
    "        #Regulated:\n",
    "        p_reg_ghost = np.zeros(len(p_reg)+2)\n",
    "        p_reg_ghost[1:-1] = p_reg\n",
    "\n",
    "        #Setting the value of the ghost points. This represents the zero flux boundary conditions. Unregulated:\n",
    "        p_unreg_ghost[0] = p_unreg[1] + 2*dg*(K/D_unreg)*(g[0]-g_peak)*p_unreg[0]\n",
    "        p_unreg_ghost[-1] = p_unreg[-2] + 2*dg*(K/D_unreg)*(g_peak-g[-1])*p_unreg[-1]\n",
    "        #Regulated:\n",
    "        p_reg_ghost[0] = p_reg[1] + 2*dg*(K/D_reg)*(g[0]-g_reg)*p_reg[0]\n",
    "        p_reg_ghost[-1] = p_reg[-2] + 2*dg*(K/D_reg)*(g_reg-g[-1])*p_reg[-1]    \n",
    "\n",
    "        #Now to solve the equation. Unregulated first:\n",
    "        p_unreg += dt*((fit - mean_wrt_P(fit,p_unreg,g))*p_unreg \\\n",
    "                    + K*derv1((g_ghost-g_peak)*p_unreg_ghost,dg) + D_unreg*derv2(p_unreg_ghost,dg))\n",
    "        p_reg += dt*((fit - mean_wrt_P(fit,p_reg,g))*p_reg \\\n",
    "                    + K*derv1((g_ghost-g_reg)*p_reg_ghost,dg) + D_reg*derv2(p_reg_ghost,dg))\n",
    "\n",
    "#         #Finally, for the edge cases, we normalize:\n",
    "#         if (flag_unreg==1 or delta>=1):\n",
    "#             p_unreg = p_unreg/np.trapz(p_unreg,dx=dg)\n",
    "#         if (flag_reg==1 or delta>=1):\n",
    "#             p_reg = p_reg/np.trapz(p_reg,dx=dg)\n",
    "            \n",
    "    return p_unreg,p_reg\n",
    "\n",
    "@jit(nopython=True)\n",
    "def selection_dyn_const_noise(p0_unreg,p0_reg,sug_dyn,K,alpha,delta,T,dt):\n",
    "    #First, time:\n",
    "    TimeRange = np.arange(0,T,dt)    \n",
    "    \n",
    "    #Then, define the fitness function:\n",
    "    s = sug_dyn[0]\n",
    "    fit = delta*(g*s/(400+s) - (2/17)*g/(1-g/(1.8*g_max)))/g_max\n",
    "    g_reg = g[np.argmax(fit)]\n",
    "\n",
    "    #Now let's compare the effects of regulation vs selection:\n",
    "    p_unreg = p0_unreg\n",
    "    p_reg = p0_reg\n",
    "    flag_unreg = 0\n",
    "    flag_reg = 0\n",
    "    \n",
    "    #Storing dynamic fitness:\n",
    "    dyn_fit_unreg, dyn_norm_fit_unreg, dyn_fit_reg, dyn_norm_fit_reg = np.zeros_like(TimeRange), np.zeros_like(TimeRange), np.zeros_like(TimeRange), np.zeros_like(TimeRange)\n",
    "    #Dynamic distributions:\n",
    "    dyn_p_unreg, dyn_p_reg = np.zeros((len(TimeRange),len(g))), np.zeros((len(TimeRange),len(g)))\n",
    "    dyn_p_unreg[0,:], dyn_p_reg[0,:] = p_unreg, p_reg    \n",
    "\n",
    "    #Now evolve it:\n",
    "    for t in range(len(TimeRange)):\n",
    "        #First setting the dynamic sugar and g_reg:\n",
    "        s = sug_dyn[t]\n",
    "        fit = delta*(g*s/(400+s) - (2/17)*g/(1-g/(1.8*g_max)))/g_max\n",
    "        g_reg = g[np.argmax(fit)]\n",
    "            \n",
    "        #Constant noise:\n",
    "        D_unreg = alpha*K*g_peak\n",
    "        D_reg = alpha*K*g_peak\n",
    "\n",
    "    #     #Checks:\n",
    "    #     if (t%10==0):\n",
    "    #         print(f\"\\nt={t}; g_mean_unreg={round(g_mean_unreg,2)}; D_unreg={round(D_unreg,2)}; max allowed={0.5*dg**2/dt}\")\n",
    "    #         print(f\"t={t}; g_mean_reg={round(g_mean_reg,2)}; D_reg={round(D_reg,2)}; max allowed={0.5*dg**2/dt}\")        \n",
    "\n",
    "        #Now creating the expanded p's, with ghost points. The bulk points are the same in each. Unregulated:\n",
    "        p_unreg_ghost = np.zeros(len(p_unreg)+2)\n",
    "        p_unreg_ghost[1:-1] = p_unreg\n",
    "        #Regulated:\n",
    "        p_reg_ghost = np.zeros(len(p_reg)+2)\n",
    "        p_reg_ghost[1:-1] = p_reg\n",
    "\n",
    "        #Setting the value of the ghost points. This represents the zero flux boundary conditions. Unregulated:\n",
    "        p_unreg_ghost[0] = p_unreg[1] + 2*dg*(K/D_unreg)*(g[0]-g_peak)*p_unreg[0]\n",
    "        p_unreg_ghost[-1] = p_unreg[-2] + 2*dg*(K/D_unreg)*(g_peak-g[-1])*p_unreg[-1]\n",
    "        #Regulated:\n",
    "        p_reg_ghost[0] = p_reg[1] + 2*dg*(K/D_reg)*(g[0]-g_reg)*p_reg[0]\n",
    "        p_reg_ghost[-1] = p_reg[-2] + 2*dg*(K/D_reg)*(g_reg-g[-1])*p_reg[-1]    \n",
    "\n",
    "        #Now to solve the equation. Unregulated first:\n",
    "        p_unreg += dt*((fit - mean_wrt_P(fit,p_unreg,g))*p_unreg \\\n",
    "                    + K*derv1((g_ghost-g_peak)*p_unreg_ghost,dg) + D_unreg*derv2(p_unreg_ghost,dg))\n",
    "        p_reg += dt*((fit - mean_wrt_P(fit,p_reg,g))*p_reg \\\n",
    "                    + K*derv1((g_ghost-g_reg)*p_reg_ghost,dg) + D_reg*derv2(p_reg_ghost,dg))\n",
    "\n",
    "#         #Finally, for the edge cases, we normalize:\n",
    "#         if (flag_unreg==1 or delta>=1): #Because apparently this blows up temporarily when delta>1\n",
    "#             p_unreg = p_unreg/np.trapz(p_unreg,dx=dg)\n",
    "#         if (flag_reg==1 or delta>=1):\n",
    "#             p_reg = p_reg/np.trapz(p_reg,dx=dg)\n",
    "            \n",
    "        #Storing the dynamic distributions:\n",
    "        dyn_p_unreg[t,:], dyn_p_reg[t,:] = p_unreg, p_reg\n",
    "            \n",
    "        #Now calculating the dynamic fitnesses, absolute:\n",
    "        dyn_fit_unreg[t] = mean_wrt_P(fit,p_unreg,g)\n",
    "        dyn_fit_reg[t] = mean_wrt_P(fit,p_reg,g)\n",
    "        #Normalized:\n",
    "        dyn_norm_fit_unreg[t] = (dyn_fit_unreg[t] - np.min(fit))/(np.max(fit) - np.min(fit))\n",
    "        dyn_norm_fit_reg[t] = (dyn_fit_reg[t] - np.min(fit))/(np.max(fit) - np.min(fit))\n",
    "            \n",
    "    return dyn_p_unreg, dyn_p_reg, dyn_fit_unreg, dyn_fit_reg\n",
    "\n",
    "@jit(nopython=True)\n",
    "def selection_dyn_scalar_output(p0_unreg,p0_reg,sug_dyn,K,alpha,delta,T,dt):\n",
    "    #First, time:\n",
    "    TimeRange = np.arange(0,T,dt)    \n",
    "    \n",
    "    #Then, define the fitness function:\n",
    "    s = sug_dyn[0]\n",
    "    fit = delta*(g*s/(400+s) - (2/17)*g/(1-g/(1.8*g_max)))/g_max\n",
    "    g_reg = g[np.argmax(fit)]\n",
    "\n",
    "    #Now let's compare the effects of regulation vs selection:\n",
    "    p_unreg = p0_unreg\n",
    "    p_reg = p0_reg\n",
    "    flag_unreg = 0\n",
    "    flag_reg = 0\n",
    "    \n",
    "    #Storing dynamic fitness:\n",
    "    dyn_fit_unreg, dyn_norm_fit_unreg, dyn_fit_reg, dyn_norm_fit_reg = np.zeros_like(TimeRange), np.zeros_like(TimeRange), np.zeros_like(TimeRange), np.zeros_like(TimeRange)\n",
    "    #Dynamic distributions:\n",
    "    dyn_p_unreg, dyn_p_reg = np.zeros((len(TimeRange),len(g))), np.zeros((len(TimeRange),len(g)))\n",
    "    dyn_p_unreg[0,:], dyn_p_reg[0,:] = p_unreg, p_reg    \n",
    "\n",
    "    #Now evolve it:\n",
    "    for t in range(len(TimeRange)):\n",
    "        #First setting the dynamic sugar and g_reg:\n",
    "        s = sug_dyn[t]\n",
    "        fit = delta*(g*s/(400+s) - (2/17)*g/(1-g/(1.8*g_max)))/g_max\n",
    "        g_reg = g[np.argmax(fit)]\n",
    "            \n",
    "        #Constant noise:\n",
    "        D_unreg = alpha*K*g_peak\n",
    "        D_reg = alpha*K*g_peak\n",
    "\n",
    "    #     #Checks:\n",
    "    #     if (t%10==0):\n",
    "    #         print(f\"\\nt={t}; g_mean_unreg={round(g_mean_unreg,2)}; D_unreg={round(D_unreg,2)}; max allowed={0.5*dg**2/dt}\")\n",
    "    #         print(f\"t={t}; g_mean_reg={round(g_mean_reg,2)}; D_reg={round(D_reg,2)}; max allowed={0.5*dg**2/dt}\")        \n",
    "\n",
    "        #Now creating the expanded p's, with ghost points. The bulk points are the same in each. Unregulated:\n",
    "        p_unreg_ghost = np.zeros(len(p_unreg)+2)\n",
    "        p_unreg_ghost[1:-1] = p_unreg\n",
    "        #Regulated:\n",
    "        p_reg_ghost = np.zeros(len(p_reg)+2)\n",
    "        p_reg_ghost[1:-1] = p_reg\n",
    "\n",
    "        #Setting the value of the ghost points. This represents the zero flux boundary conditions. Unregulated:\n",
    "        p_unreg_ghost[0] = p_unreg[1] + 2*dg*(K/D_unreg)*(g[0]-g_peak)*p_unreg[0]\n",
    "        p_unreg_ghost[-1] = p_unreg[-2] + 2*dg*(K/D_unreg)*(g_peak-g[-1])*p_unreg[-1]\n",
    "        #Regulated:\n",
    "        p_reg_ghost[0] = p_reg[1] + 2*dg*(K/D_reg)*(g[0]-g_reg)*p_reg[0]\n",
    "        p_reg_ghost[-1] = p_reg[-2] + 2*dg*(K/D_reg)*(g_reg-g[-1])*p_reg[-1]    \n",
    "\n",
    "        #Now to solve the equation. Unregulated first:\n",
    "        p_unreg += dt*((fit - mean_wrt_P(fit,p_unreg,g))*p_unreg \\\n",
    "                    + K*derv1((g_ghost-g_peak)*p_unreg_ghost,dg) + D_unreg*derv2(p_unreg_ghost,dg))\n",
    "        p_reg += dt*((fit - mean_wrt_P(fit,p_reg,g))*p_reg \\\n",
    "                    + K*derv1((g_ghost-g_reg)*p_reg_ghost,dg) + D_reg*derv2(p_reg_ghost,dg))\n",
    "\n",
    "#         #Finally, for the edge cases, we normalize:\n",
    "#         if (flag_unreg==1 or delta>=1): #Because apparently this blows up temporarily when delta>1\n",
    "#             p_unreg = p_unreg/np.trapz(p_unreg,dx=dg)\n",
    "#         if (flag_reg==1 or delta>=1):\n",
    "#             p_reg = p_reg/np.trapz(p_reg,dx=dg)\n",
    "            \n",
    "        #Storing the dynamic distributions:\n",
    "        dyn_p_unreg[t,:], dyn_p_reg[t,:] = p_unreg, p_reg\n",
    "            \n",
    "        #Now calculating the dynamic fitnesses, absolute:\n",
    "        dyn_fit_unreg[t] = mean_wrt_P(fit,p_unreg,g)\n",
    "        dyn_fit_reg[t] = mean_wrt_P(fit,p_reg,g)\n",
    "        #Normalized:\n",
    "        dyn_norm_fit_unreg[t] = (dyn_fit_unreg[t] - np.min(fit))/(np.max(fit) - np.min(fit))\n",
    "        dyn_norm_fit_reg[t] = (dyn_fit_reg[t] - np.min(fit))/(np.max(fit) - np.min(fit))\n",
    "        #The long-term fitnesses:\n",
    "        long_term_fit_unreg = np.trapz(dyn_fit_unreg,dx=dt)\n",
    "        long_term_fit_reg = np.trapz(dyn_fit_reg,dx=dt)\n",
    "            \n",
    "    return long_term_fit_unreg, long_term_fit_reg\n",
    "\n",
    "def logistic_sigmoid(x,height,pos,slope):\n",
    "    return height/(1 + np.exp(-slope*(x-pos)))\n",
    "\n",
    "def exponential_growth(x,a,b):\n",
    "    return a*np.exp(b*x)\n",
    "\n",
    "def linear_growth(x,a,b):\n",
    "    return a*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b07df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Now we initialize the parameters:\n",
    "# K = 0.01\n",
    "# delta = 1\n",
    "# alpha = 0.5\n",
    "# tau = 100\n",
    "\n",
    "# #Constant environment, T fixed:\n",
    "# dt = np.minimum(0.00005/K,0.005/delta)\n",
    "# # dt = 0.0001/K\n",
    "# # T = 10\n",
    "# # #If tau is too large, we don't change:\n",
    "# num_cycles = 16\n",
    "# T = num_cycles*tau\n",
    "# TimeRange = np.arange(0,T,dt)\n",
    "# print(\"No. of timepoints: \",len(TimeRange))\n",
    "# print(\"dt: \",dt)\n",
    "\n",
    "# # The noise variance D:\n",
    "# D = alpha*K*g_peak\n",
    "\n",
    "# #Checks:\n",
    "# print(f\"K = {K}; 0.5*dg/dt = {0.5*dg/dt}\")\n",
    "# print(f\"D = {D}; 0.5*dg**2/dt = {0.5*dg**2/dt}\")\n",
    "\n",
    "# #Stability check:\n",
    "# flag_stability=0\n",
    "# if (K>=int(0.5*dg/dt) or D>=int(0.5*dg**2/dt)):\n",
    "#     flag_stability=1\n",
    "#     print(\"Warning! FTCS unstable.\")\n",
    "\n",
    "# #The initial distributions:\n",
    "# p0_unreg = Gaussian(g,g_peak,np.maximum(np.sqrt(alpha*g_peak),1))\n",
    "# p0_unreg = p0_unreg/np.trapz(p0_unreg,dx=dg)\n",
    "# p0_reg = p0_unreg\n",
    "# p0_reg = p0_reg/np.trapz(p0_reg,dx=dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cacbd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag = False\n",
    "# sug_dyn = np.ones_like(TimeRange)\n",
    "# temp_sug = np.array([])\n",
    "\n",
    "# #The sugars:\n",
    "# sug_low = 68\n",
    "# sug_high = 400\n",
    "\n",
    "# for i in range(num_cycles):\n",
    "#     if (i%2==0):\n",
    "#         temp_sug = np.concatenate((temp_sug,sug_low*np.array_split(sug_dyn,num_cycles)[i]))\n",
    "#     elif (i%2==1):\n",
    "#         temp_sug = np.concatenate((temp_sug,sug_high*np.array_split(sug_dyn,num_cycles)[i]))\n",
    "# sug_dyn = temp_sug\n",
    "\n",
    "# fig,ax = plt.subplots(1,1)\n",
    "\n",
    "# ax.plot(TimeRange/tau,sug_dyn,c='k')\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "# # ax.set_xlabel(r'Time $t$',fontsize=18)\n",
    "# # ax.set_ylabel('Sugar $s$',fontsize=18)\n",
    "# ax.set_title('Sugar vs. time', fontsize=20)\n",
    "# ax.set_box_aspect(1)\n",
    "# ax.set_xticks((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47d81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Finding the g_opt as a function of time through sugar:\n",
    "# g_opt_dyn = np.ones_like(sug_dyn)\n",
    "\n",
    "# g_opt_low = g[np.argmax(fitness(g,sug_low,delta))]\n",
    "# g_opt_high = g[np.argmax(fitness(g,sug_high,delta))]\n",
    "\n",
    "# temp_g_opt = np.array([])\n",
    "# for i in range(num_cycles):\n",
    "#     if (i%2==0):\n",
    "#         temp_g_opt = np.concatenate((temp_g_opt,g_opt_low*np.array_split(g_opt_dyn,num_cycles)[i]))\n",
    "#     elif (i%2==1):\n",
    "#         temp_g_opt = np.concatenate((temp_g_opt,g_opt_high*np.array_split(g_opt_dyn,num_cycles)[i]))\n",
    "# g_opt_dyn = temp_g_opt\n",
    "\n",
    "# # for sug_idx in range(len(sug_dyn)):\n",
    "# #     g_opt_dyn[sug_idx] = g[np.argmax(fitness(g,sug_dyn[sug_idx],delta))]\n",
    "\n",
    "# # G,S = np.meshgrid(g,sug_dyn)\n",
    "# # fitness_2d = fitness(G,S,delta)\n",
    "# # g_opt_dyn = g[np.argmax(fitness_2d,axis=1)]\n",
    "\n",
    "# fig,ax = plt.subplots(1,1)\n",
    "# ax.set_ylim(bottom=g_min,top=g_max)\n",
    "# ax.plot(TimeRange/tau,g_opt_dyn,'k')\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "# ax.set_xlabel(r'Time $t$',fontsize=18)\n",
    "# ax.set_ylabel(r'$\\hat{g}_s$',fontsize=18)\n",
    "# ax.set_title('Optimal expression vs. time', fontsize=20)\n",
    "# ax.set_xticks((0,2,4))\n",
    "# ax.set_box_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490e833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dyn_p_unreg, dyn_p_reg, dyn_fit_unreg, dyn_norm_fit_unreg, dyn_fit_reg, dyn_norm_fit_reg = selection_dyn_const_noise(p0_unreg,p0_reg,sug_dyn,K,alpha,delta,T,dt)\n",
    "# dyn_fit_unreg, dyn_fit_reg = selection_dyn_const_noise(p0_unreg,p0_reg,sug_dyn,K,alpha,delta,T,dt)[2:]\n",
    "# overall_fitness_unreg = np.trapz(dyn_fit_unreg,dx=dt)\n",
    "# overall_fitness_reg = np.trapz(dyn_fit_reg,dx=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b696b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Now varying K, delta, alpha:\n",
    "# K_arr = np.array([0.02,0.05,0.1,0.2,0.5])\n",
    "# delta_arr = np.array([0.1,0.5,2.5,12.5])\n",
    "# alpha_arr = np.array([0.5,4.5,12.5])\n",
    "\n",
    "# long_term_fit_unreg = np.zeros((len(K_arr),len(delta_arr),len(alpha_arr)))\n",
    "# long_term_fit_reg = np.zeros((len(K_arr),len(delta_arr),len(alpha_arr)))\n",
    "\n",
    "# for K_idx in range(len(K_arr)):\n",
    "#     for delta_idx in range(len(delta_arr)):\n",
    "#         for alpha_idx in range(len(alpha_arr)):\n",
    "\n",
    "#             #Now we initialize the parameters:\n",
    "#             K = K_arr[K_idx]\n",
    "#             delta = delta_arr[delta_idx]\n",
    "#             alpha = alpha_arr[alpha_idx]\n",
    "#             tau = 10\n",
    "\n",
    "#             #Constant environment, T fixed:\n",
    "#             dt = np.minimum(0.00005/K,0.005/delta)\n",
    "#             # dt = 0.0001/K\n",
    "#             # T = 10\n",
    "#             # #If tau is too large, we don't change:\n",
    "#             num_cycles = 8\n",
    "#             T = num_cycles*tau\n",
    "#             TimeRange = np.arange(0,T,dt)\n",
    "\n",
    "#             # The noise variance D:\n",
    "#             D = alpha*K*g_peak\n",
    "\n",
    "# #             #Checks:\n",
    "# #             print(f\"K = {K}; 0.5*dg/dt = {0.5*dg/dt}\")\n",
    "# #             print(f\"D = {D}; 0.5*dg**2/dt = {0.5*dg**2/dt}\")\n",
    "\n",
    "#             #Stability check:\n",
    "#             flag_stability=0\n",
    "#             if (K>=int(0.5*dg/dt) or D>=int(0.5*dg**2/dt)):\n",
    "#                 flag_stability=1\n",
    "#                 print(\"Warning! FTCS unstable.\")\n",
    "                \n",
    "#             print(f\"K,delta,alpha: {K, delta, alpha}\\n\")\n",
    "\n",
    "#             #The initial distributions:\n",
    "#             p0_unreg = Gaussian(g,g_peak,np.maximum(np.sqrt(alpha*g_peak),1))\n",
    "#             p0_unreg = p0_unreg/np.trapz(p0_unreg,dx=dg)\n",
    "#             p0_reg = p0_unreg\n",
    "#             p0_reg = p0_reg/np.trapz(p0_reg,dx=dg)\n",
    "            \n",
    "#             #The dynamic sugar environment:\n",
    "#             flag = False\n",
    "#             sug_dyn = np.ones_like(TimeRange)\n",
    "#             temp_sug = np.array([])\n",
    "#             #The sugars:\n",
    "#             sug_low = 68\n",
    "#             sug_high = 400\n",
    "#             for i in range(num_cycles):\n",
    "#                 if (i%2==0):\n",
    "#                     temp_sug = np.concatenate((temp_sug,sug_low*np.array_split(sug_dyn,num_cycles)[i]))\n",
    "#                 elif (i%2==1):\n",
    "#                     temp_sug = np.concatenate((temp_sug,sug_high*np.array_split(sug_dyn,num_cycles)[i]))\n",
    "#             sug_dyn = temp_sug\n",
    "            \n",
    "#             #The optimal g:\n",
    "#             g_opt_dyn = np.ones_like(sug_dyn)\n",
    "#             g_opt_low = g[np.argmax(fitness(g,sug_low,delta))]\n",
    "#             g_opt_high = g[np.argmax(fitness(g,sug_high,delta))]\n",
    "#             temp_g_opt = np.array([])\n",
    "#             for i in range(num_cycles):\n",
    "#                 if (i%2==0):\n",
    "#                     temp_g_opt = np.concatenate((temp_g_opt,g_opt_low*np.array_split(g_opt_dyn,num_cycles)[i]))\n",
    "#                 elif (i%2==1):\n",
    "#                     temp_g_opt = np.concatenate((temp_g_opt,g_opt_high*np.array_split(g_opt_dyn,num_cycles)[i]))\n",
    "#             g_opt_dyn = temp_g_opt\n",
    "            \n",
    "#             #Now solving the equation:\n",
    "#             long_term_fit_unreg[K_idx,delta_idx,alpha_idx],long_term_fit_reg[K_idx,delta_idx,alpha_idx] = selection_dyn_scalar_output(p0_unreg,p0_reg,sug_dyn,K,alpha,delta,T,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b501c6",
   "metadata": {},
   "source": [
    "## The parameter scans of excess fitness by regulation vs $K \\tau$, $\\delta \\tau$, and $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e1893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #To save:\n",
    "# # #np.savetxt(\"dynamic_env_long_term_fit_unreg_12012023.txt\",long_term_fit_unreg.flatten())\n",
    "# # #np.savetxt(\"dynamic_env_long_term_fit_reg_12012023.txt\",long_term_fit_reg.flatten())\n",
    "\n",
    "# #To load:\n",
    "# test1 = np.loadtxt(\"dynamic_env_long_term_fit_unreg_12012023.txt\").reshape(5,4,3)\n",
    "# test2 = np.loadtxt(\"dynamic_env_long_term_fit_reg_12012023.txt\").reshape(5,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba5a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pic_vmin = np.min(long_term_fit_reg/long_term_fit_unreg - 1)*0.98\n",
    "# pic_vmax = np.max(long_term_fit_reg/long_term_fit_unreg - 1)*1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbeca117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Let's visualize the output:\n",
    "# # plt.imshow(fit_norm_unreg.T,cmap=no_reg_cmp,origin=\"lower\")\n",
    "# alpha_idx = 0\n",
    "# fig,ax = plt.subplots(1,1,constrained_layout='true')\n",
    "# pic=ax.imshow(long_term_fit_reg[:,:,alpha_idx]/long_term_fit_unreg[:,:,alpha_idx] - 1,cmap='gray',origin='lower',vmin=pic_vmin,vmax=pic_vmax)\n",
    "# cbar = plt.colorbar(pic)\n",
    "# ax.set_xticks(ticks=range(4),labels=np.around(delta_arr*tau,decimals=2))\n",
    "# ax.set_yticks(ticks=range(5),labels=np.around(K_arr*tau,decimals=2))\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "# ax.set_ylabel(r'$K \\tau$',fontsize=18)\n",
    "# ax.set_xlabel(r'$\\delta \\tau$',fontsize=18)\n",
    "# ax.set_title(fr'$\\alpha = {np.around(np.sqrt(alpha_arr[alpha_idx]*g_peak)/g_max,2)}$',fontsize=20)\n",
    "# # fig.savefig(f\"excess_fitness_by_reg_alpha={np.sqrt(alpha_arr[alpha_idx]*g_peak)/g_max}.pdf\",format=\"pdf\",dpi=400,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e48dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_idx = 1\n",
    "# fig,ax = plt.subplots(1,1,constrained_layout='true')\n",
    "# pic=ax.imshow(long_term_fit_reg[:,:,alpha_idx]/long_term_fit_unreg[:,:,alpha_idx] - 1,cmap='gray',origin='lower',vmin=pic_vmin,vmax=pic_vmax)\n",
    "# cbar = plt.colorbar(pic)\n",
    "# ax.set_xticks(ticks=range(4),labels=np.around(delta_arr*tau,decimals=2))\n",
    "# ax.set_yticks(ticks=range(5),labels=np.around(K_arr*tau,decimals=2))\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "# # ax.set_ylabel(r'$K \\tau$',fontsize=18)\n",
    "# ax.set_xlabel(r'$\\delta \\tau$',fontsize=18)\n",
    "# ax.set_title(fr'$\\alpha = {np.around(np.sqrt(alpha_arr[alpha_idx]*g_peak)/g_max,2)}$',fontsize=20)\n",
    "# # fig.savefig(f\"excess_fitness_by_reg_alpha={np.sqrt(alpha_arr[alpha_idx]*g_peak)/g_max}.pdf\",format=\"pdf\",dpi=400,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61133f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_idx = 2\n",
    "# fig,ax = plt.subplots(1,1,constrained_layout='true')\n",
    "# pic=ax.imshow(long_term_fit_reg[:,:,alpha_idx]/long_term_fit_unreg[:,:,alpha_idx] - 1,cmap='gray',origin='lower',vmin=pic_vmin,vmax=pic_vmax)\n",
    "# cbar = plt.colorbar(pic)\n",
    "# ax.set_xticks(ticks=range(4),labels=np.around(delta_arr*tau,decimals=2))\n",
    "# ax.set_yticks(ticks=range(5),labels=np.around(K_arr*tau,decimals=2))\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "# ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "# # ax.set_ylabel(r'$K \\tau$',fontsize=18)\n",
    "# ax.set_xlabel(r'$\\delta \\tau$',fontsize=18)\n",
    "# ax.set_title(fr'$\\alpha = {np.around(np.sqrt(alpha_arr[alpha_idx]*g_peak)/g_max,2)}$',fontsize=20)\n",
    "# # fig.savefig(f\"excess_fitness_by_reg_alpha={np.sqrt(alpha_arr[alpha_idx]*g_peak)/g_max}.pdf\",format=\"pdf\",dpi=400,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafeb439",
   "metadata": {},
   "source": [
    "## Excess fitness for fixed $\\delta / K$ for various $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8ff933",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_arr = np.logspace(start=np.log10(0.02),stop=np.log10(0.5),num=7)\n",
    "delta_by_K_arr = np.array([1,5,25])\n",
    "alpha_arr = np.array([0.5,4.5,12.5])\n",
    "\n",
    "# long_term_fit_unreg = np.zeros((len(K_arr),len(delta_by_K_arr),len(alpha_arr)))\n",
    "# long_term_fit_reg = np.zeros((len(K_arr),len(delta_by_K_arr),len(alpha_arr)))\n",
    "\n",
    "# for K_idx in range(len(K_arr)):\n",
    "#     for delta_by_K_idx in range(len(delta_by_K_arr)):\n",
    "#         for alpha_idx in range(len(alpha_arr)):\n",
    "\n",
    "#             #Now we initialize the parameters:\n",
    "#             K = K_arr[K_idx]\n",
    "#             delta = delta_by_K_arr[delta_by_K_idx]*K\n",
    "#             alpha = alpha_arr[alpha_idx]\n",
    "#             tau = 10\n",
    "\n",
    "#             #Constant environment, T fixed:\n",
    "#             dt = np.minimum(0.00005/K,0.005/delta)\n",
    "#             # dt = 0.0001/K\n",
    "#             # T = 10\n",
    "#             # #If tau is too large, we don't change:\n",
    "#             num_cycles = 8\n",
    "#             T = num_cycles*tau\n",
    "#             TimeRange = np.arange(0,T,dt)\n",
    "\n",
    "#             # The noise variance D:\n",
    "#             D = alpha*K*g_peak\n",
    "\n",
    "# #             #Checks:\n",
    "# #             print(f\"K = {K}; 0.5*dg/dt = {0.5*dg/dt}\")\n",
    "# #             print(f\"D = {D}; 0.5*dg**2/dt = {0.5*dg**2/dt}\")\n",
    "\n",
    "#             #Stability check:\n",
    "#             flag_stability=0\n",
    "#             if (K>=int(0.5*dg/dt) or D>=int(0.5*dg**2/dt)):\n",
    "#                 flag_stability=1\n",
    "#                 print(\"Warning! FTCS unstable.\")\n",
    "                \n",
    "#             print(f\"K,delta,alpha: {K, delta, alpha}\")\n",
    "\n",
    "#             #The initial distributions:\n",
    "#             p0_unreg = Gaussian(g,g_peak,np.maximum(np.sqrt(alpha*g_peak),1))\n",
    "#             p0_unreg = p0_unreg/np.trapz(p0_unreg,dx=dg)\n",
    "#             p0_reg = p0_unreg\n",
    "#             p0_reg = p0_reg/np.trapz(p0_reg,dx=dg)\n",
    "            \n",
    "#             #The dynamic sugar environment:\n",
    "#             flag = False\n",
    "#             sug_dyn = np.ones_like(TimeRange)\n",
    "#             temp_sug = np.array([])\n",
    "#             #The sugars:\n",
    "#             sug_low = 68\n",
    "#             sug_high = 400\n",
    "#             for i in range(num_cycles):\n",
    "#                 if (i%2==0):\n",
    "#                     temp_sug = np.concatenate((temp_sug,sug_low*np.array_split(sug_dyn,num_cycles)[i]))\n",
    "#                 elif (i%2==1):\n",
    "#                     temp_sug = np.concatenate((temp_sug,sug_high*np.array_split(sug_dyn,num_cycles)[i]))\n",
    "#             sug_dyn = temp_sug\n",
    "            \n",
    "#             #The optimal g:\n",
    "#             g_opt_dyn = np.ones_like(sug_dyn)\n",
    "#             g_opt_low = g[np.argmax(fitness(g,sug_low,delta))]\n",
    "#             g_opt_high = g[np.argmax(fitness(g,sug_high,delta))]\n",
    "#             temp_g_opt = np.array([])\n",
    "#             for i in range(num_cycles):\n",
    "#                 if (i%2==0):\n",
    "#                     temp_g_opt = np.concatenate((temp_g_opt,g_opt_low*np.array_split(g_opt_dyn,num_cycles)[i]))\n",
    "#                 elif (i%2==1):\n",
    "#                     temp_g_opt = np.concatenate((temp_g_opt,g_opt_high*np.array_split(g_opt_dyn,num_cycles)[i]))\n",
    "#             g_opt_dyn = temp_g_opt\n",
    "            \n",
    "#             #Now solving the equation:\n",
    "#             long_term_fit_unreg[K_idx,delta_by_K_idx,alpha_idx],long_term_fit_reg[K_idx,delta_by_K_idx,alpha_idx] = selection_dyn_scalar_output(p0_unreg,p0_reg,sug_dyn,K,alpha,delta,T,dt)\n",
    "            \n",
    "#             print(f\"long term fitness, unreg and reg: {long_term_fit_unreg[K_idx,delta_by_K_idx,alpha_idx],long_term_fit_reg[K_idx,delta_by_K_idx,alpha_idx]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366ac6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # #To save:\n",
    "# # # # np.savetxt(\"long_term_fit_unreg_fixed_delta-K_ratio_13012023.txt\",long_term_fit_unreg.flatten())\n",
    "# # # # np.savetxt(\"long_term_fit_reg_fixed_delta-K_ratio_13012023.txt\",long_term_fit_reg.flatten())\n",
    "\n",
    "# #To load:\n",
    "# result1 = np.loadtxt(\"long_term_fit_unreg_fixed_delta-K_ratio_13012023.txt\").reshape(7,3,3)\n",
    "# result2 = np.loadtxt(\"long_term_fit_reg_fixed_delta-K_ratio_13012023.txt\").reshape(7,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "080c605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 10\n",
    "# ylim_max = np.max(result2/result1 - 1)*1.1\n",
    "# ylim_min = np.min(result2/result1 - 1)*0.4\n",
    "\n",
    "# fit_params = np.zeros((len(delta_by_K_arr),len(alpha_arr),3))\n",
    "\n",
    "# for delta_by_K_idx in range(len(delta_by_K_arr)):\n",
    "#     for alpha_idx in range(len(alpha_arr)):\n",
    "#         popt,pcov = sciopt.curve_fit(logistic_sigmoid,K_arr,(result2/result1 - 1)[:,delta_by_K_idx,alpha_idx],p0=([1,1,1]),maxfev = 10000)\n",
    "#         fit_params[delta_by_K_idx,alpha_idx] = popt\n",
    "        \n",
    "# K_axis = np.logspace(start=np.log10(0.02),stop=np.log10(0.5),num=51)\n",
    "\n",
    "# colors_grey = ['#b3b3b3','#666666','#000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "508e91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_by_K_idx = 0\n",
    "\n",
    "# fig,ax = plt.subplots(1,1,constrained_layout='true')\n",
    "\n",
    "# for alpha_idx in range(len(alpha_arr)):\n",
    "#     ax.scatter(K_arr,(result2/result1 - 1)[:,delta_by_K_idx,alpha_idx],c=colors_grey[alpha_idx])\n",
    "#     ax.plot(K_axis,logistic_sigmoid(K_axis,*fit_params[delta_by_K_idx,alpha_idx]),c=colors_grey[alpha_idx],ls='--',\\\n",
    "#             label=fr'max = {np.around(fit_params[delta_by_K_idx,alpha_idx,0],2)}')\n",
    "\n",
    "# ax.set_ylim([ylim_min,ylim_max])\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_xticks(K_arr)\n",
    "# ax.set_xticklabels(np.around(K_arr*tau,1))\n",
    "# ax.minorticks_off()\n",
    "# ax.set_box_aspect(1)\n",
    "# ax.set_xlabel(r'$K \\tau$',fontsize=18)\n",
    "# ax.set_ylabel(r'excess fitness',fontsize=18)\n",
    "# ax.set_title(fr'$\\delta / K = {delta_by_K_arr[delta_by_K_idx]}$',fontsize=20)\n",
    "# ax.legend(loc='best')\n",
    "# fig.set_figheight(3.6)\n",
    "# fig.savefig(f\"ex_fit_del_by_K={delta_by_K_arr[delta_by_K_idx]}.pdf\",format=\"pdf\",dpi=400,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1a44ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_by_K_idx = 1\n",
    "\n",
    "# fig,ax = plt.subplots(1,1,constrained_layout='true')\n",
    "\n",
    "# for alpha_idx in range(len(alpha_arr)):\n",
    "#     ax.scatter(K_arr,(result2/result1 - 1)[:,delta_by_K_idx,alpha_idx],c=colors_grey[alpha_idx])\n",
    "#     ax.plot(K_axis,logistic_sigmoid(K_axis,*fit_params[delta_by_K_idx,alpha_idx]),c=colors_grey[alpha_idx],ls='--',\\\n",
    "#             label=fr'max = {np.around(fit_params[delta_by_K_idx,alpha_idx,0],2)}')\n",
    "\n",
    "# ax.set_ylim([ylim_min,ylim_max])\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_xticks(K_arr)\n",
    "# ax.set_xticklabels(np.around(K_arr*tau,1))\n",
    "# ax.minorticks_off()\n",
    "# ax.set_box_aspect(1)\n",
    "# ax.set_xlabel(r'$K \\tau$',fontsize=18)\n",
    "# # ax.set_ylabel(r'excess fitness',fontsize=18)\n",
    "# ax.set_title(fr'$\\delta / K = {delta_by_K_arr[delta_by_K_idx]}$',fontsize=20)\n",
    "# ax.legend(loc='best')\n",
    "# fig.set_figheight(3.6)\n",
    "# fig.savefig(f\"ex_fit_del_by_K={delta_by_K_arr[delta_by_K_idx]}.pdf\",format=\"pdf\",dpi=400,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ba9d7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_by_K_idx = 2\n",
    "\n",
    "# fig,ax = plt.subplots(1,1,constrained_layout='true')\n",
    "\n",
    "# for alpha_idx in range(len(alpha_arr)):\n",
    "#     ax.scatter(K_arr,(result2/result1 - 1)[:,delta_by_K_idx,alpha_idx],c=colors_grey[alpha_idx])\n",
    "#     ax.plot(K_axis,logistic_sigmoid(K_axis,*fit_params[delta_by_K_idx,alpha_idx]),c=colors_grey[alpha_idx],ls='--',\\\n",
    "#             label=fr'$\\alpha = {np.sqrt(alpha_arr[alpha_idx]*g_peak)/g_max}$, max = {np.around(fit_params[delta_by_K_idx,alpha_idx,0],2)}')\n",
    "    \n",
    "# ax.set_ylim([ylim_min,ylim_max])\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_xticks(K_arr)\n",
    "# ax.set_xticklabels(np.around(K_arr*tau,1))\n",
    "# ax.minorticks_off()\n",
    "# ax.set_box_aspect(1)\n",
    "# ax.set_xlabel(r'$K \\tau$',fontsize=18)\n",
    "# # ax.set_ylabel(r'excess fitness',fontsize=18)\n",
    "# ax.set_title(fr'$\\delta / K = {delta_by_K_arr[delta_by_K_idx]}$',fontsize=20)\n",
    "# ax.legend(loc='best')\n",
    "# fig.set_figheight(3.6)\n",
    "# fig.savefig(f\"ex_fit_del_by_K={delta_by_K_arr[delta_by_K_idx]}.pdf\",format=\"pdf\",dpi=400,bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
